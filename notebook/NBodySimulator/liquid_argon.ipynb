{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Liquid argon benchmarks\n### Sebastian Micluța-Câmpeanu, Mikhail Vaganov\n\nThe purpose of these benchmarks is to compare several integrators for use in\nmolecular dynamics simulation. We will use a simulation of liquid argon form the\nexamples of NBodySimulator as test case."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using ProgressLogging\nusing NBodySimulator, OrdinaryDiffEq, StaticArrays\nusing Plots, DataFrames, StatsPlots\n\nfunction setup(t)\n    T = 120.0 # K\n    kb = 1.38e-23 # J/K\n    ϵ = T * kb # J\n    σ = 3.4e-10 # m\n    ρ = 1374 # kg/m^3\n    m = 39.95 * 1.6747 * 1e-27 # kg\n    N = 350\n    L = (m*N/ρ)^(1/3)\n    R = 3.5σ\n    v_dev = sqrt(kb * T / m) # m/s\n\n    _L = L / σ\n    _σ = 1.0\n    _ϵ = 1.0\n    _m = 1.0\n    _v = v_dev / sqrt(ϵ / m)\n    _R = R / σ\n\n    bodies = generate_bodies_in_cell_nodes(N, _m, _v, _L)\n    lj_parameters = LennardJonesParameters(_ϵ, _σ, _R)\n    pbc = CubicPeriodicBoundaryConditions(_L)\n    lj_system = PotentialNBodySystem(bodies, Dict(:lennard_jones => lj_parameters));\n    simulation = NBodySimulation(lj_system, (0.0, t), pbc, _ϵ/T)\n\n    return simulation\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to compare different integrating methods we will consider a fixed simulation\ntime and change the timestep (or tolerances in the case of adaptive methods)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function benchmark(energyerr, rts, bytes, allocs, nt, nf, t, configs)\n    simulation = setup(t)\n    prob = SecondOrderODEProblem(simulation)\n    for config in configs\n        alg = config.alg\n        sol, rt, b, gc, memalloc = @timed solve(prob, alg();\n            save_everystep=false, progress=true, progress_name=\"$alg\", config...)\n        result = NBodySimulator.SimulationResult(sol, simulation)\n        ΔE = total_energy(result, t) - total_energy(result, 0)\n        energyerr[alg] = ΔE\n        rts[alg] = rt\n        bytes[alg] = b\n        allocs[alg] = memalloc\n        nt[alg] = sol.destats.naccept\n        nf[alg] = sol.destats.nf + sol.destats.nf2\n    end\nend\n\nfunction run_benchmark!(results, t, integrators, tol...; c=ones(length(integrators)))\n    @progress \"Benchmark at t=$t\" for τ in zip(tol...)\n        runtime = Dict()\n        ΔE = Dict()\n        nt = Dict()\n        nf = Dict()\n        b = Dict()\n        allocs = Dict()\n        cfg = config(integrators, c, τ...)\n\n        GC.gc()\n        benchmark(ΔE, runtime, b, allocs, nt, nf, t, cfg)\n        get_tol(idx) = haskey(cfg[idx], :dt) ? cfg[idx].dt : (cfg[idx].abstol, cfg[idx].rtol)\n\n        for (idx,i) in enumerate(integrators)\n            push!(results, [string(i), runtime[i], get_tol(idx)..., abs(ΔE[i]), nt[i], nf[i], c[idx]])\n        end\n    end\n    return results\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will consider symplectic integrators first"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "symplectic_integrators = [\n    VelocityVerlet,\n    VerletLeapfrog,\n    PseudoVerletLeapfrog,\n    McAte2,\n    CalvoSanz4,\n    McAte5,\n    Yoshida6,\n    KahanLi8,\n    SofSpa10\n];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since for each method there is a different cost for a timestep, we need to take that\ninto account when choosing the tolerances (`dt`s or `abstol`&`reltol`) for the \nsolvers. This cost was estimated using the commented code below and the\nresults were hardcoded in order to prevent fluctuations in the results\nbetween runs due to differences in callibration times.\n\nThe calibration is based on running a simulation with equal tolerances for all\nsolvers and then computing the cost as the runtime / number of timesteps.\nThe absolute value of the cost is not very relevant, so the cost was normalized\nto the cost of one `VelocityVerlet` step."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "config(integrators, c, τ) = [ (alg=a, dt=τ*cₐ) for (a,cₐ) in zip(integrators, c)]\n\nt = 35.0\nτs = 1e-3\n\n# warmup\nc_symplectic = ones(length(symplectic_integrators))\nbenchmark(Dict(), Dict(), Dict(), Dict(), Dict(), Dict(), 10.,\n    config(symplectic_integrators, c_symplectic, τs))\n\n# results = DataFrame(:integrator=>String[], :runtime=>Float64[], :τ=>Float64[],\n#     :EnergyError=>Float64[], :timesteps=>Int[], :f_evals=>Int[], :cost=>Float64[]);\n# run_benchmark!(results, t, symplectic_integrators, τs)\n\n# c_symplectic .= results[!, :runtime] ./ results[!, :timesteps]\n# c_Verlet = c_symplectic[1]\n# c_symplectic /= c_Verlet\n\nc_symplectic = [\n    1.00,   # VelocityVerlet\n    1.05,   # VerletLeapfrog\n    0.98,   # PseudoVerletLeapfrog\n    1.02,   # McAte2\n    2.38,   # CalvoSanz4\n    2.92,   # McAte5\n    3.74,   # Yoshida6\n    8.44,   # KahanLi8\n    15.76   # SofSpa10\n]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now benchmark the solvers for a fixed simulation time and variable timestep"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "t = 40.0\nτs = 10 .^range(-4, -3, length=10)\n\nresults = DataFrame(:integrator=>String[], :runtime=>Float64[], :τ=>Float64[],\n    :EnergyError=>Float64[], :timesteps=>Int[], :f_evals=>Int[], :cost=>Float64[]);\nrun_benchmark!(results, t, symplectic_integrators, τs, c=c_symplectic)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The energy error as a function of runtime is given by"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@df results plot(:EnergyError, :runtime, group=:integrator,\n    xscale=:log10, yscale=:log10, xlabel=\"Energy error\", ylabel=\"Runtime (s)\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the runtime as a function of timesteps, we can observe that we have\na linear dependency for each method, and the slope is the previously computed\ncost per step."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@df results plot(:timesteps, :runtime, group=:integrator,\n    xscale=:log10, yscale=:log10, xlabel=\"Number of timesteps\", ylabel=\"Runtime (s)\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look at the energy error history"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function benchmark(energyerr, rts, ts, t, configs)\n    simulation = setup(t)\n    prob = SecondOrderODEProblem(simulation)\n    for config in configs\n        alg = config.alg\n        sol, rt = @timed solve(prob, alg(); progress=true, progress_name=\"$alg\", config...)\n        result = NBodySimulator.SimulationResult(sol, simulation)\n        ΔE(t) = total_energy(result, t) - total_energy(result, 0)\n        energyerr[alg] = [ΔE(t) for t in sol.t[2:10^2:end]]\n        rts[alg] = rt\n        ts[alg] = sol.t[2:10^2:end]\n    end\nend\n\nΔE = Dict()\nrt = Dict()\nts = Dict()\nconfigs = config(symplectic_integrators, c_symplectic, 2.3e-4)\nbenchmark(ΔE, rt, ts, 40., configs)\n\nplt = plot(xlabel=\"Rescaled Time\", ylabel=\"Energy error\", legend=:bottomleft);\nfor c in configs\n    plot!(plt, ts[c.alg], abs.(ΔE[c.alg]), label=\"$(c.alg), $(rt[c.alg])s\")\nend\nplt"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us compare some adaptive methods"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "adaptive_integrators=[\n    # Non-stiff ODE methods\n    Tsit5,\n    Vern7,\n    Vern9,\n    # DPRKN\n    DPRKN6,\n    DPRKN8,\n    DPRKN12,\n];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly to the case of symplectic methods, we will take into account the average cost per timestep\nin order to have a fair comparison between the solvers."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "config(integrators, c, at, rt) = [ (alg=a, abstol=at*2^cₐ, rtol=rt*2^cₐ) for (a,cₐ) in zip(integrators, c)]\n\nt = 35.0\nats = 10 .^range(-14, -4, length=10)\nrts = 10 .^range(-14, -4, length=10)\n\n# warmup\nc_adaptive = ones(length(adaptive_integrators))\nbenchmark(Dict(), Dict(), Dict(), Dict(), Dict(), Dict(), 10.,\n    config(adaptive_integrators, 1, ats[1], rts[1]))\n\n# results = DataFrame(:integrator=>String[], :runtime=>Float64[], :abstol=>Float64[],\n#    :reltol=>Float64[], :EnergyError=>Float64[], :timesteps=>Int[], :f_evals=>Int[], :cost=>Float64[]);\n# run_benchmark!(results, t, adaptive_integrators, ats[1], rts[1])\n\n# c_adaptive .= results[!, :runtime] ./ results[!, :timesteps]\n# c_adaptive /= c_Verlet\n\nc_adaptive = [\n    3.55,   # Tsit5,\n    7.84,   # Vern7,\n    11.38,  # Vern9\n    3.56,   # DPRKN6,\n    5.10,   # DPRKN8,\n    8.85    # DPRKN12,\n]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now benchmark the solvers for a fixed simulation time and variable timestep"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "t = 40.0\n\nresults = DataFrame(:integrator=>String[], :runtime=>Float64[], :abstol=>Float64[],\n    :reltol=>Float64[], :EnergyError=>Float64[], :timesteps=>Int[], :f_evals=>Int[], :cost=>Float64[]);\nrun_benchmark!(results, t, adaptive_integrators, ats, rts, c=c_adaptive)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The energy error as a function of runtime is given by"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@df results plot(:EnergyError, :runtime, group=:integrator,\n    xscale=:log10, yscale=:log10, xlabel=\"Energy error\", ylabel=\"Runtime (s)\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we consider the number of function evaluations instead, we obtain"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@df results plot(:EnergyError, :f_evals, group=:integrator,\n    xscale=:log10, yscale=:log10, xlabel=\"Energy error\", ylabel=\"Number of f evals\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now compare the best performing solvers"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "t = 40.0\n\nsymplectic_integrators = [\n    VelocityVerlet,\n    VerletLeapfrog,\n    PseudoVerletLeapfrog,\n    McAte2,\n    CalvoSanz4\n]\n\nc_symplectic = [\n    1.00,   # VelocityVerlet\n    1.05,   # VerletLeapfrog\n    0.98,   # PseudoVerletLeapfrog\n    1.02,   # McAte2\n    2.38,   # CalvoSanz4\n]\n\nresults1 = DataFrame(:integrator=>String[], :runtime=>Float64[], :τ=>Float64[],\n    :EnergyError=>Float64[], :timesteps=>Int[], :f_evals=>Int[], :cost=>Float64[]);\nrun_benchmark!(results1, t, symplectic_integrators, τs, c=c_symplectic)\n\nadaptive_integrators=[\n    DPRKN6,\n    DPRKN8,\n    DPRKN12,\n]\n\nc_adaptive = [\n    3.56,   # DPRKN6,\n    5.10,   # DPRKN8,\n    8.85    # DPRKN12,\n]\n\nresults2 = DataFrame(:integrator=>String[], :runtime=>Float64[], :abstol=>Float64[],\n    :reltol=>Float64[], :EnergyError=>Float64[], :timesteps=>Int[], :f_evals=>Int[], :cost=>Float64[]);\nrun_benchmark!(results2, t, adaptive_integrators, ats, rts, c=c_adaptive)\n\nappend!(results1, results2, cols=:union)\nresults1"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The energy error as a function of runtime is given by"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@df results1 plot(:EnergyError, :runtime, group=:integrator,\n    xscale=:log10, yscale=:log10, xlabel=\"Energy error\", ylabel=\"Runtime (s)\")"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.4.2"
    },
    "kernelspec": {
      "name": "julia-1.4",
      "display_name": "Julia 1.4.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
